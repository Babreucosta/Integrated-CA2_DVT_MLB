{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd44276",
   "metadata": {},
   "source": [
    "<div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:arial;text-align:center;display:fill;border-radius:5px; letter-spacing: 2px; background-color:#257CCB;overflow:hidden\"><b>INTEGRATED CONTINUOUS ASSESSMENT</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a5be77",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "<h2 style=\"font-family:arial;text-align:center; font-size: 32px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: centre; letter-spacing: 5px; color:#257CCB; background-color: #ffffff;\"> <b>DATA VISUALISATION + MACHINE LEARNING</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35284fbd",
   "metadata": {},
   "source": [
    "Programme Title: HDIP Data Analytics\n",
    "\n",
    "Cohort: HDIP Feb 22 FT/PT\n",
    "\n",
    "Module Title(s): Data Visualization Techniques & Machine Learning for Business \n",
    "\n",
    "Assignment Type: Individual  \n",
    "\n",
    "Assignment Title: Integrated CA2_DVT_MLB\n",
    "\n",
    "Lecturer(s): David McQuaid & Dr. Muhammad Iqba\n",
    "\n",
    "Issue Date: 19th October 2023  \n",
    "\n",
    "Submission Deadline Date:  26th November 2023 \n",
    "\n",
    "Student: **_Bárbara Abreu Costa 2023099_**\n",
    "\n",
    "GitHub Repository: https://github.com/Babreucosta/Integrated-CA2_DVT_MLB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab5f8e",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd9868",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <p style=\"padding:10px;background-color:#257CCB;margin:0;color:white;font-family:arial;font-size:100%;text-align:center;border-radius:5px;overflow:hidden;font-weight:500\">_MACHINE LEARNING_</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c57c5",
   "metadata": {},
   "source": [
    "**QUESTION 1**\n",
    "\n",
    "Discuss and explain the purpose of a recommendation system for online retail business in machine\n",
    "learning. Briefly compare Content and Collaborative filtering using any dataset of your choice (Datasets used\n",
    "in the class tutorials or exercises are not allowed to use in this CA2). Train and test machine learning models\n",
    "for the user-user or item-item collaborative filtering. Justify your recommendations for the considered\n",
    "scenario by providing a conceptual insight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985e3df",
   "metadata": {},
   "source": [
    "> **_RECOMMENDATION SYSTEM PURPOSE_**\n",
    "> \n",
    "> Recommendation systems play a pivotal role in the success of online retail businesses by leveraging machine learning algorithms to deliver personalized product suggestions to users. It analyze a user's historical behavior, preferences, and interactions with the platform to offer product suggestions tailored to their individual tastes and needs. This personalization creates a more engaging and relevant shopping experience. \n",
    "> \n",
    "> One of the primary purposes of a recommendation system is to augment the customer experience. By presenting relevant products to users based on their past interactions, the system assists in narrowing down choices from a vast array of offerings. This not only saves time for the customer but also creates a sense of personalization, fostering customer loyalty. For instance, Amazon's recommendation engine analyzes user behavior and provides suggestions such as \"Customers who bought this also bought...\" or \"Recommended for you\", contributing significantly to their sales revenue (Linden et al., 2003).\n",
    ">\n",
    "> Another vital purpose of recommendation systems is to facilitate cross-selling and up-selling opportunities. Cross-selling involves suggesting related or complementary products to the user's current selection, while up-selling involves recommending higher-value alternatives. \n",
    ">\n",
    "> In conclusion, recommendation systems are indispensable tools for online retail businesses, leveraging machine learning techniques to enhance the customer experience, increase sales, alleviate information overload, and drive cross-selling and up-selling initiatives. Through personalized suggestions, these systems create a win-win situation, benefiting both the customer and the retailer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c796f1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f3a46",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "<h2 style=\"font-family:arial;text-align:center; font-size: 32px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: centre; letter-spacing: 3px; color:#257CCB; background-color: #ffffff;\"> <b>SUPERSTORE SALES</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99189a1b",
   "metadata": {},
   "source": [
    "This dataset is having the data of 1K+ Amazon Product's Ratings and Reviews as per their details listed on the official website of Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dc7aca",
   "metadata": {},
   "source": [
    "##### DICTIONARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e52c1e",
   "metadata": {},
   "source": [
    "| STT | ATTRIBUTE NAME | MEANING |\n",
    "|:---| :--- |:--- |\n",
    "| 0 | product_id | Product ID\n",
    "| 1 |product_name | Name of the Product\n",
    "| 2 |category | Category of the Product\n",
    "| 3 |discounted_price | Discounted Price of the Product\n",
    "| 4 |actual_price | Actual Price of the Product\n",
    "| 5 |discount_percentage | Percentage of Discount for the Product\n",
    "| 6 |rating | Rating of the Product\n",
    "| 7 |rating_count | Number of people who voted for the Amazon rating\n",
    "| 8 |about_product | Description about the Product\n",
    "| 9 |user_id | ID of the user who wrote review for the Product\n",
    "| 10 |user_name | Name of the user who wrote review for the Product\n",
    "| 11 |review_id | ID of the user review\n",
    "| 12 |review_title | Short review\n",
    "| 13 |review_content | Long review\n",
    "| 14 |img_link | Image Link of the Product\n",
    "| 15 |product_link | Official Website Link of the Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ef68c",
   "metadata": {},
   "source": [
    "##### DATA UNDERSTANDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84da413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa4d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Superstore.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7a01600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2013-152156</td>\n",
       "      <td>2013-11-09</td>\n",
       "      <td>2013-11-12</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2013-152156</td>\n",
       "      <td>2013-11-09</td>\n",
       "      <td>2013-11-12</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2013-138688</td>\n",
       "      <td>2013-06-13</td>\n",
       "      <td>2013-06-17</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90036</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2012-108966</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>2012-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2012-108966</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>2012-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2013-152156 2013-11-09 2013-11-12    Second Class    CG-12520   \n",
       "1       2  CA-2013-152156 2013-11-09 2013-11-12    Second Class    CG-12520   \n",
       "2       3  CA-2013-138688 2013-06-13 2013-06-17    Second Class    DV-13045   \n",
       "3       4  US-2012-108966 2012-10-11 2012-10-18  Standard Class    SO-20335   \n",
       "4       5  US-2012-108966 2012-10-11 2012-10-18  Standard Class    SO-20335   \n",
       "\n",
       "     Customer Name    Segment        Country             City  ...  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "\n",
       "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
       "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "\n",
       "                                        Product Name     Sales  Quantity  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       "\n",
       "   Discount    Profit  \n",
       "0      0.00   41.9136  \n",
       "1      0.00  219.5820  \n",
       "2      0.00    6.8714  \n",
       "3      0.45 -383.0310  \n",
       "4      0.20    2.5164  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1f1092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read with utf-8 encoding.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Try reading the file with different encodings\n",
    "encodings_to_try = ['utf-8', 'latin1', 'ISO-8859-1', 'cp1252']\n",
    "file_path = 'Superstore.csv'\n",
    "\n",
    "for encoding in encodings_to_try:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding=encoding)\n",
    "        # If successful, break the loop\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to read with {encoding} encoding.\")\n",
    "\n",
    "# Now df should contain the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71257bb9",
   "metadata": {},
   "source": [
    "##### MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(dataframe):\n",
    "    return dataframe.isnull().sum()\n",
    "\n",
    "print(check_missing_values(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42858343",
   "metadata": {},
   "source": [
    "##### DUPLICATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be51f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(dataframe):\n",
    "    return dataframe.duplicated().sum()\n",
    "\n",
    "print(check_duplicates(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf3fd57",
   "metadata": {},
   "source": [
    "##### DATA TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_types(dataframe):\n",
    "    return dataframe.dtypes\n",
    "\n",
    "print(check_data_types(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97304596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invoice date has wrong data type, we will fix it\n",
    "df['invoice_date'] = pd.to_datetime(df['invoice_date'], dayfirst=True)\n",
    "\n",
    "#Also, we create new columns for year and month that can be useful for further analysis\n",
    "df['year'] = df['invoice_date'].dt.strftime(\"%Y\")\n",
    "df['month'] = df['invoice_date'].dt.strftime(\"%m\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76602d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive information about dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column total money spent, which will be useful later\n",
    "df['total spent'] = df['price'] * df['quantity']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column with age group\n",
    "age_groups = [18, 24, 34, 44, 54, 64, 70]\n",
    "labels = ['18-24','25-34','35-44','45-54','55-64','65-70']\n",
    "df['age_group'] = pd.cut(df['age'],bins=age_groups, labels =labels)\n",
    "age_cats = pd.CategoricalDtype(['18-24','25-34','35-44','45-54','55-64','65-70'], ordered=True)\n",
    "df['age_group'] = df['age_group'].astype(age_cats)\n",
    "df.head()\n",
    "\n",
    "#Seems like now our data has all necessary columns, correct datatypes, no duplicates or \n",
    "#missing entires. And ready for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652cff6",
   "metadata": {},
   "source": [
    "##### VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f0eb1",
   "metadata": {},
   "source": [
    "Analyze the distribution of customer ratings using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6517ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, investigate gender columns and see if we get some insights\n",
    "sns.countplot(data=df,x='gender').set(title='Gender and number of transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build histogram of age distribution per number of transactions\n",
    "sns.histplot(data=df, x='age_group').set(title = 'Age distribution and number of transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which age group spent more money?\n",
    "age_group_total = df.groupby('age_group')['total'].sum().reset_index()\n",
    "sns.barplot(data=age_group_total, x='age_group', y='total', palette = 'Paired').\\\n",
    "set(title='Age group and total spent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore payment methods\n",
    "sns.countplot(x='payment_method', data=df).set(title='Payment method and number of transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34178cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most customers are paying by cash. But what about the amount of money spent and payment method?\n",
    "df_payment = pd.DataFrame(df.groupby('payment_method')['total'].sum())\n",
    "df_payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ae74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate which products price customers usually prefer\n",
    "df.price.hist()\n",
    "plt.title('Price distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed24895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover popular categories\n",
    "df_category_count = df.groupby('category')['invoice_no'].count().reset_index()\n",
    "df_category_count.sort_values(by='invoice_no', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a79b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize popular categories per number of transactions and total amount spent\n",
    "df_category_total = df.groupby('category')['total'].sum().reset_index()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10))\n",
    "sns.barplot(data=df_category_count, x='category', y='invoice_no', ax = ax1).set(title='Categories and number of transactions')\n",
    "sns.barplot(data=df_category_total, x='category', y = 'total', ax = ax2).set(title='Categories and total amount spent')\n",
    "ax1.tick_params('x', labelrotation=45)\n",
    "ax2.tick_params('x', labelrotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea917de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the average price per category?\n",
    "avg_price_category = pd.DataFrame(df.groupby('category')['price'].mean().sort_values(ascending=False))\n",
    "avg_price_category.columns = ['average_price']\n",
    "avg_price_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution number of transaction per age groups and gender\n",
    "pd.crosstab([df.age_group, df.gender], df.category, values=df.invoice_no, aggfunc=(['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdab2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most popular shopping malls by number of transactions\n",
    "pd.DataFrame(df['shopping_mall'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f4217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb7709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b556c11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cbada8b",
   "metadata": {},
   "source": [
    "##### RECOMENTATION SYSTEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc16cee",
   "metadata": {},
   "source": [
    "> To achieve this goal, I am developing a recommendation system using an Amazon dataset encompassing 1462 rows, with key columns including 'product_name', 'category', 'discounted_price', 'actual_price', among others. Leveraging this dataset, I will build a tailored recommendation engine capable of suggesting products based on a user's browsing history and preferences. This means that upon logging in, users will receive personalized product recommendations, enhancing their shopping experience by introducing them to new and relevant items. This personalized approach aims to make their shopping journey more enjoyable and convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac8d80",
   "metadata": {},
   "source": [
    "###### 1. USER-BASED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815fb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['customer_id_encoded'] = le.fit_transform(df['customer_id'])\n",
    "\n",
    "# Create a new dataframe with the user_id frequency table\n",
    "freq_table = pd.DataFrame({'User ID': df['customer_id_encoded'].value_counts().index, 'Frequency': df['customer_id_encoded'].value_counts().values})\n",
    "\n",
    "# Display the dataframe\n",
    "print(freq_table)\n",
    "id_example = freq_table.iloc[0,0]\n",
    "print(id_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec993ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any irrelevant columns for the recommendation system\n",
    "columns_to_drop = ['invoice_no', 'invoice_date']  # Assuming these columns are not relevant for recommendations\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Handle missing values if any\n",
    "df.dropna(inplace=True)  # Drop rows with missing values for simplicity (Handle based on your data and context)\n",
    "\n",
    "# Encode categorical variables if needed\n",
    "# Example: Convert categorical variables like 'gender', 'category', 'payment_method', 'shopping_mall' into numerical values using label encoding or one-hot encoding\n",
    "# For label encoding:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "# Repeat this for other categorical columns\n",
    "\n",
    "# Normalize numerical columns if needed (optional step, depends on your algorithm and data)\n",
    "# Example: Normalize 'age', 'quantity', 'price' columns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[['age', 'quantity', 'price']] = scaler.fit_transform(df[['age', 'quantity', 'price']])\n",
    "\n",
    "# Check if the data looks appropriate after preprocessing\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1553dc6",
   "metadata": {},
   "source": [
    "> Prepare the data for building the recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ea135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the user-item matrix or any other appropriate data structure based on the recommendation technique you choose\n",
    "# For example, create a user-item matrix for collaborative filtering\n",
    "# You might pivot the data to get a matrix where rows represent customers, columns represent items, and the values are interactions (e.g., purchase quantity)\n",
    "user_item_matrix = df.pivot_table(index='customer_id', columns='category', values='quantity', fill_value=0)\n",
    "\n",
    "# Check the user-item matrix\n",
    "print(user_item_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370a0dd",
   "metadata": {},
   "source": [
    "> Build the recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Assuming you have a sparse user-item matrix\n",
    "sparse_user_item_matrix = csr_matrix(user_item_matrix.values)\n",
    "\n",
    "# Compute similarity using sparse matrix\n",
    "sparse_similarity_matrix = cosine_similarity(sparse_user_item_matrix)\n",
    "\n",
    "# Get recommendations using the sparse similarity matrix\n",
    "recommendations_sparse = get_recommendations(customer_id_to_recommend, sparse_similarity_matrix, user_item_matrix)\n",
    "print(\"Recommendations for Customer\", customer_id_to_recommend, \":\", recommendations_sparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose and implement a recommendation algorithm\n",
    "# Example: Use collaborative filtering algorithm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate similarity matrix using cosine similarity\n",
    "similarity_matrix = cosine_similarity(user_item_matrix)\n",
    "\n",
    "# Create a function to get recommendations for a given customer\n",
    "def get_recommendations(customer_id, similarity_matrix, user_item_matrix):\n",
    "    customer_index = user_item_matrix.index.get_loc(customer_id)\n",
    "    similar_users = similarity_matrix[customer_index]\n",
    "    similar_users_indexes = similar_users.argsort()[::-1][1:]  # Exclude the customer's own index\n",
    "    \n",
    "    recommendations = []\n",
    "    for index in similar_users_indexes:\n",
    "        similar_user_id = user_item_matrix.iloc[index].name\n",
    "        items_bought_by_similar_user = user_item_matrix.iloc[index]\n",
    "        items_not_bought_by_customer = items_bought_by_similar_user[items_bought_by_similar_user == 0]\n",
    "        recommendations.extend(items_not_bought_by_customer.index.tolist())\n",
    "    \n",
    "    return recommendations[:10]  # Return top 10 recommendations\n",
    "\n",
    "# Get recommendations for a specific customer\n",
    "customer_id_to_recommend = 123  # Replace with the actual customer ID\n",
    "recommendations = get_recommendations(customer_id_to_recommend, similarity_matrix, user_item_matrix)\n",
    "print(\"Recommendations for Customer\", customer_id_to_recommend, \":\", recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b454d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Reduce dimensions\n",
    "svd = TruncatedSVD(n_components=100)  # Experiment with different values\n",
    "user_item_matrix_reduced = svd.fit_transform(user_item_matrix)\n",
    "\n",
    "# Calculate similarity matrix using the reduced matrix\n",
    "similarity_matrix_reduced = cosine_similarity(user_item_matrix_reduced)\n",
    "\n",
    "# Get recommendations using the reduced matrix\n",
    "recommendations_reduced = get_recommendations(customer_id_to_recommend, similarity_matrix_reduced, user_item_matrix_reduced)\n",
    "print(\"Recommendations for Customer\", customer_id_to_recommend, \":\", recommendations_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64887231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Read the dataset\n",
    "df = pd.read_csv('customer_shopping_data.csv')\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "# You might need to handle missing values, encode categorical variables, etc.\n",
    "# For item-item collaborative filtering, focus on items and their characteristics\n",
    "\n",
    "# Step 3: Encode categorical variables if needed\n",
    "label_encoder = LabelEncoder()\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# Step 4: Create item-item similarity matrix\n",
    "# Group data by items and find their characteristics\n",
    "item_features = df.groupby('category_encoded').agg({'price': 'mean', 'quantity': 'sum'}).reset_index()\n",
    "\n",
    "# Step 5: Calculate cosine similarity between items based on features\n",
    "item_similarity = cosine_similarity(item_features[['price', 'quantity']])\n",
    "\n",
    "# Step 6: Function to get similar items for a given item\n",
    "def get_similar_items(item_id, top_n=5):\n",
    "    similar_items = []\n",
    "    item_index = item_features[item_features['category_encoded'] == item_id].index[0]\n",
    "    sim_scores = list(enumerate(item_similarity[item_index]))\n",
    "\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:top_n + 1]\n",
    "\n",
    "    for i, score in sim_scores:\n",
    "        similar_items.append({\n",
    "            'category_encoded': item_features.iloc[i]['category_encoded'],\n",
    "            'similarity_score': score\n",
    "        })\n",
    "\n",
    "    return similar_items\n",
    "\n",
    "# Step 7: Get similar items for a specific item (example: item_id = 3)\n",
    "similar_items = get_similar_items(item_id=3, top_n=5)\n",
    "print(similar_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51496126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features (price and quantity)\n",
    "scaler = StandardScaler()\n",
    "df[['price', 'quantity']] = scaler.fit_transform(df[['price', 'quantity']])\n",
    "# Scaling helps to standardize the range of values and improve similarity calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_similarity(item_features):\n",
    "    # Implement your custom similarity metric based on domain knowledge\n",
    "    # Example: Euclidean distance between normalized features\n",
    "    normalized_features = (item_features - item_features.mean()) / item_features.std()\n",
    "    similarity = 1 / (1 + np.sqrt(np.sum((normalized_features - normalized_features.mean()) ** 2)))\n",
    "    return similarity\n",
    "\n",
    "# Calculate similarity using the custom function\n",
    "custom_item_similarity = custom_similarity(item_features[['price', 'quantity']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c52ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-compute similarity using modified features\n",
    "item_similarity = cosine_similarity(item_features[['price', 'quantity']])\n",
    "# or use the custom similarity metric\n",
    "# item_similarity = custom_similarity(item_features[['price', 'quantity']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0206bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3473e28f",
   "metadata": {},
   "source": [
    "#  (!) INLCUDE COMENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b09617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df686f30",
   "metadata": {},
   "source": [
    "   ###### 2. CONTENT-BASED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print plot overviews of the first 10 review content.\n",
    "df['review_content'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "# Replace NaN with an empty string\n",
    "df['review_content'] = df['review_content'].fillna('')\n",
    "\n",
    "# Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df['review_content'])\n",
    "\n",
    "# Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0beedb7",
   "metadata": {},
   "source": [
    "> Array mapping from feature integer indices to feature name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e00235",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.get_feature_names_out()[5000:5010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9866460",
   "metadata": {},
   "source": [
    "> From the above output, you observe that 13826 different vocabularies or words in your dataset have 1462 review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d455100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix[:10000], tfidf_matrix[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd727e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba46f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7aea31",
   "metadata": {},
   "source": [
    "##### CALCULATE PRODUCT SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14091f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'product_name' and 'review_content' into a single text column\n",
    "df['text'] = df['product_name'] + ' ' + df['review_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b83d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TF-IDF vectorization to 'text' column\n",
    "tfidf_matrix = vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9235255",
   "metadata": {},
   "source": [
    "##### GET PRODUCT RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b25c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_recommendations(product_id, num_recommendations=5):\n",
    "    # Get the index of the product with the given ID\n",
    "    index = df[df['product_id'] == product_id].index[0]\n",
    "\n",
    "    # Get the pairwise similarity scores of the product\n",
    "    sim_scores = list(enumerate(cosine_sim[index]))\n",
    "\n",
    "    # Sort the products based on similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top N similar products\n",
    "    top_products = [df.iloc[score[0]] for score in sim_scores[1:num_recommendations+1]]\n",
    "\n",
    "    return top_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8586a",
   "metadata": {},
   "source": [
    "> Now we can replace 'product_id' with any product id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = 'B08CF3B7N1'  \n",
    "recommendations = get_product_recommendations(product_id)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee4e01a",
   "metadata": {},
   "source": [
    "#  (!) INLCUDE COMENT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce86690",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e9c7a",
   "metadata": {},
   "source": [
    "**QUESTION 2**\n",
    "\n",
    "Perform Market Basket Analysis on the chosen dataset by using Apriori and FP growth algorithms. Can\n",
    "you express major divergence between these models? Compare and contrast the machine learning results\n",
    "obtained based on both algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0baef",
   "metadata": {},
   "source": [
    "> **Market basket analysis** - consider products that are frequently reviewed together as being bought together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('amazon.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3e497",
   "metadata": {},
   "source": [
    "# produto x categoria\n",
    "# categoria x produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d594d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74425111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948fd442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.DataFrame(df[['user_id']].value_counts(), columns=['values'])\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5ab8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a basket for each user\n",
    "basket = (df.groupby(['user_id', 'product_id'])['rating_count']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('user_id'))\n",
    "\n",
    "print(basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49331a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and declare a method named as 'encode_units()'\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "\n",
    "basket_sets = basket.applymap(encode_units)\n",
    "\n",
    "basket_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5543e4d",
   "metadata": {},
   "source": [
    "# Apriori Rule for Market Basket Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dac77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(basket_sets, min_support = 0.02, use_colnames = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d482352",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_itemsets, metric = \"lift\", min_threshold = 5)\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc97fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34d924a2",
   "metadata": {},
   "source": [
    "# FP-growth algorithm for Market Basket Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c614ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the frequent item rules for fpgrowth function\n",
    "frequent_itemsets_fp1 = fpgrowth(basket_sets, min_support = 0.1, use_colnames = True)\n",
    "\n",
    "print(frequent_itemsets_fp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba65d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8097a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori algorithm\n",
    "frequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)\n",
    "\n",
    "# Print frequent itemsets for inspection\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Association Rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "# Print rules for inspection\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43dcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2e52218",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <p style=\"padding:10px;background-color:#257CCB;margin:0;color:white;font-family:arial;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:500\">_DATA VISUALISATION_</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b4c58",
   "metadata": {},
   "source": [
    "**QUESTION 3**\n",
    "\n",
    "Create an interactive Dashboard aimed at older adults (65+) with specific features to summarise the most\n",
    "important aspects of the data and identify through your visualisation why this dataset is suitable for\n",
    "Machine Learning models in an online retail business. Explain how your dashboard is designed with this\n",
    "demographic in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610a5a15",
   "metadata": {},
   "source": [
    "https://www.bing.com/images/search?q=python+dashboard&form=HDRSC3&first=1&cw=1177&ch=689"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d2f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191907c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('amazon.csv')\n",
    "\n",
    "# Visualization 1: Bar chart for product categories\n",
    "category_counts = df['category'].value_counts().reset_index()\n",
    "category_counts.columns = ['Category', 'Count']\n",
    "\n",
    "fig1 = px.bar(category_counts, x='Category', y='Count', title='Product Categories Distribution')\n",
    "fig1.show()\n",
    "\n",
    "# Visualization 2: Line chart for sales trends\n",
    "sales_trends = df.groupby('product_name')['rating_count'].sum().reset_index().sort_values(by='rating_count', ascending=False)[:10]\n",
    "\n",
    "fig2 = px.line(sales_trends, x='product_name', y='rating_count', title='Top 10 Products by Rating Count')\n",
    "fig2.show()\n",
    "\n",
    "# Visualization 3: Pie chart for product ratings distribution\n",
    "rating_distribution = df['rating'].value_counts().reset_index()\n",
    "rating_distribution.columns = ['Rating', 'Count']\n",
    "\n",
    "fig3 = px.pie(rating_distribution, values='Count', names='Rating', title='Product Ratings Distribution')\n",
    "fig3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_data.csv' with the actual file path or URL of your Amazon dataset\n",
    "amazon_data = pd.read_csv('amazon.csv')\n",
    "\n",
    "# Perform any necessary data preprocessing\n",
    "# For example, aggregate sales data by month\n",
    "discount_data = amazon_data.groupby('category')['discount_percentage'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc413de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dashboard app\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "# Define the layout of the dashboard\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Amazon Online Retail Dashboard\"),\n",
    "    \n",
    "    # Sales Trends Line Chart\n",
    "    dcc.Graph(\n",
    "        id='sales-trends',\n",
    "        figure=px.line(discount_data, x='category', y='discount_percentage', title='Monthly Sales Trends')\n",
    "    ),\n",
    "\n",
    "    # Product Category Pie Chart\n",
    "    dcc.Graph(\n",
    "        id='product-categories',\n",
    "        figure=px.pie(amazon_data, names='product_id', title='Product Category Distribution')\n",
    "    ),\n",
    "\n",
    "    # Customer Reviews Sentiment Heatmap\n",
    "    # (Note: This is a simplified example, and sentiment analysis requires additional processing)\n",
    "    dcc.Graph(\n",
    "        id='sentiment-heatmap',\n",
    "        figure=px.imshow([[0.8, 0.2], [0.4, 0.6]], color_continuous_scale='Viridis', title='Customer Reviews Sentiment')\n",
    "    )\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db7b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8304eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ad21c16",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <p style=\"padding:10px;background-color:#257CCB;margin:0;color:white;font-family:arial;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:500\">_TITLE HERE_</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014bcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd4cc257",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <p style=\"padding:10px;background-color:#257CCB;margin:0;color:white;font-family:arial;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:500\">_REFERENCES_</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7a5b0",
   "metadata": {},
   "source": [
    "(22/10)\n",
    " \n",
    "https://stackoverflow.com/questions/14088687/how-to-change-plot-background-color\n",
    "    \n",
    "https://datascientyst.com/full-list-named-colors-pandas-python-matplotlib/\n",
    "\n",
    "https://htmlcolorcodes.com/\n",
    "\n",
    "Amazon Customer Reviews (dataset) https://www.tensorflow.org/datasets/catalog/amazon_us_reviews\n",
    "\n",
    "https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/datasets/amazon_us_reviews/dummy_data/test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1bdde2",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "Linden, G., Smith, B., & York, J. (2003). Amazon.com recommendations: Item-to-item collaborative filtering. IEEE Internet Computing, 7(1), 76-80.\n",
    "\n",
    "Yin, D., Hong, L., Davison, B. D., & Sidiropoulos, N. (2012). Comparative recommendation: A study of effectiveness metrics. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval (pp. 339-348).\n",
    "\n",
    "McFee, B., Lanckriet, G. R., & Lanckriet, G. R. (2012). Metric learning to rank. In Advances in neural information processing systems (pp. 2573-2581).\n",
    "\n",
    "Kang, J., McAuley, J., & Leskovec, J. (2012). Exploring patterns of activity on e-commerce sites. In Proceedings of the 21st international conference on World Wide Web (pp. 795-804)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5348a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
